{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMMXLENOd7V-"
   },
   "source": [
    "# Wstęp do Sztucznej Inteligencji - rok akademicki 2020/2021\n",
    "\n",
    "Przed rozpoczęciem pracy z notatnikiem zmień jego nazwę zgodnie z wzorem: `NrAlbumu_Nazwisko_Imie_PoprzedniaNazwa`.\n",
    "\n",
    "Przed wysłaniem notatnika upewnij się, że rozwiązałeś wszystkie zadania/ćwiczenia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZZF68t-kiQ8"
   },
   "source": [
    "# Temat: Sztuczne Sieci Neuronowe - Lab 3 - Zadania (obowiązkowe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKQDY1HADZWP"
   },
   "source": [
    "# Biblioteka Keras. Aspekty uczenia sieci neuronowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwgxhLoJ1uGq"
   },
   "source": [
    "## Sieci neuronowe w języku Python\n",
    "Obecnie za sprawą rozwoju i popularności tzw. głębokich sieci neuronowych (Deep Neural Network) dostępnych jest bardzo dużo bibliotek/frameworków do budowy i uczenia sieci neuronowych (TensorFlow, Theano, Spark MLlib, MXNet, Microsoft Cognitive Toolkit, Caffe itp.). Z wielu z nich można korzystać w prosty sposób przy wykorzystaniu języka  Python.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTpCaibN1Ccp"
   },
   "source": [
    "## Biblioteka Keras (na TensorFlow)\n",
    "Biblioteka Keras jest wysokopoziomową nakładką na biblioteki takie jak TensorFlow, CNTK (Microsoft Cognitive Toolkit) lub Theano napisaną w języku Python. Domyślnie wykorzystywanym backendem jest TensorFlow i z takiego będziemy korzystać. Biblioteka ta pozwala na:\n",
    "- Łatwe i szybkie prototypowanie modeli (pełna modularność).\n",
    "- Wspiera zarówno \"klasyczne\" sieci neuronowe jak i konwolucyjne czy rekurencyjne. \n",
    "- Umożliwia uczenie przy wykorzystaniu CPU oraz GPU.\n",
    "\n",
    "Keras: https://keras.io/\n",
    "\n",
    "TensorFlow: https://www.tensorflow.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rx6b2MiJ2tig"
   },
   "source": [
    "## Szybkie wprowadzenie na przykładzie sieci dla problemu XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJZNQVlLEDWe"
   },
   "source": [
    "### Dane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iSvDMwjcEGfk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_x = np.array([[-1,-1],[-1,1],[1,-1],[1,1]])  # backpropagation nie lubi zer, bez biasu\n",
    "data_y = np.array([0,1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Co4Gjp8vEZ09"
   },
   "source": [
    "### Import biblioteki Tensorflow i Keras\n",
    "Biblioteke Kreas można zaimportować bezpośrednio `import keras` Jednak obecnie bublioteka Keras jest również dostępna jako podmoduł biblioteki Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NmjUUb9QEfsz",
    "outputId": "36df215a-434c-41df-9ff8-1dabc00f8a63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.5.0\n",
      "Keras z tensorflow version: 2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "print('Keras z tensorflow version:', tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9B7YUblnktrz"
   },
   "source": [
    "### Przygotowanie architektury sieci\n",
    "Stworzenie sieci MLP o dwóch neuronach ukrytych i jednym wyjściowym:\n",
    "\n",
    "Tworzenie modelu odbywa się na zasadzie budowania modelu z klocków (warstw). Najpierw tworzymy tensor będący warstwą wejściową `Input` a następnie dodajemy do niego kojejne warstwy np. `Dense` (warstwa neuronów typu każdy z każdym). Następnie dysponując tensorem wejściowym i wyjściowym określamy Model. Model można tworzyć też z wykorzystaniem klasy `Sequential`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UuHygHS8Gkj2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qdHlPqvoGDwn"
   },
   "outputs": [],
   "source": [
    "x = Input(shape=(2,))  #należy ustawić kształ tensora wejściowego\n",
    "h = Dense(2, use_bias=True, activation='tanh', kernel_initializer='random_uniform', bias_initializer='random_uniform')(x)   #parametry patrz dokumentacja\n",
    "y = Dense(1, use_bias=True, activation='sigmoid', kernel_initializer='random_uniform', bias_initializer='random_uniform')(h)  # parametry patrz dokumentacja\n",
    "# alternatywnie activation można ustawić na None i dodać funkcje aktywacj jako osobną warstwę\n",
    "mlp = Model(inputs=x, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BP3EyefoHI30",
    "outputId": "03d20a45-cd46-4af7-c768-e89c77e2e1e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IZKS6bzcVFM"
   },
   "source": [
    "### Kompilacja modelu\n",
    "Po stworzeniu modelu należy go skompilować, podczas kompilacji podajemy m.in. rodzaj funkcji używanej do liczenia błędu (`loss`) oraz algorytm wykorzystywany do uczenia (`optimizer`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rWmaaK9DH-HP",
    "outputId": "64678297-7b7d-43bd-9c42-17a1d29e5050"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "rms = tf.keras.optimizers.RMSprop(lr=0.01)  #lr = learning rate; parametry patrz dokumentacja\n",
    "mlp.compile(loss='mse', optimizer=rms)  #mse = mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2vtgnMxcqEP"
   },
   "source": [
    "### Uczenie\n",
    "Po kompilacji możemy przystąpić do uczenia za pomocą metody `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60Lf6k1yINb0",
    "outputId": "cf1b0065-167b-4b3d-8f21-0cccb0dc9cef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rozpoczecie uczenia\n",
      "Epoch 1/300\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 0.2500\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2501\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2500\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2500\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2500\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2500\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2499\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2498\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2495\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2492\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2487\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2481\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2474\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2464\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2454\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2441\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2428\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2413\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2397\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2379\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2361\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2342\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2322\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2302\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2281\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2259\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2237\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2215\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2192\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2168\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2145\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2121\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2097\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2073\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2049\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2024\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2000\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1975\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1951\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1926\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1902\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1877\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1853\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1828\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1804\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1779\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1755\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1731\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1707\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1684\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1660\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1637\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1613\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1590\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1567\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1544\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1522\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1499\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1477\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1455\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1433\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1412\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1390\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1369\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1348\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1328\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1307\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1287\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1267\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1247\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1228\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1208\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1189\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1170\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1152\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1134\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1115\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1098\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1080\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1062\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1045\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1028\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1012\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0995\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0979\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0963\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0947\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0932\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0916\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0901\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0886\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0871\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0857\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0843\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0829\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0815\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0801\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0788\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0775\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0762\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0749\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0736\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0724\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0712\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0700\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0688\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0676\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0665\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0654\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0642\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0632\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0621\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0610\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0600\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0590\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0580\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0570\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0560\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0551\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0541\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0532\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0523\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0514\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0505\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0496\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0488\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0480\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0471\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0463\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0455\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0448\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0440\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0432\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0425\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0418\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0410\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0403\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0396\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0390\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0383\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0376\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0370\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0364\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0357\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0351\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0345\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0339\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0333\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0328\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0322\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0317\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0311\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0306\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0301\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0295\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0290\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0285\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0280\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0276\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0271\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0266\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0262\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0257\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0253\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0248\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0244\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0240\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0236\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0232\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0228\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0224\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0220\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0216\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0213\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0202\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0198\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0195\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0192\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0188\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0185\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0182\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0179\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0176\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0170\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0167\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0164\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0161\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0159\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0153\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0151\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0148\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0146\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0143\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0141\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0138\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0136\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0134\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0131\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0129\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0127\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0125\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0123\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0121\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0119\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0117\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0115\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0113\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0111\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0109\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0107\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0105\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0103\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0102\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0100\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0098\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0097\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0095\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0093\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0092\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0090\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0089\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0087\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0086\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0084\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0083\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0081\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0080\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0079\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0077\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0076\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0075\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0074\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0072\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0071\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0070\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0069\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0068\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0066\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0065\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0064\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0063\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0062\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0061\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0060\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0059\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0058\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0057\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0056\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0055\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0054\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0053\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0052\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0052\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0051\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0050\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0048\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0047\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0047\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0046\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0045\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0044\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0044\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0043\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0042\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0041\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0041\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0040\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0039\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0039\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0038\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0037\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0037\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0036\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0036\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0035\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0034\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0034\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0033\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0033\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0032\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0032\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0031\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0031\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0030\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0030\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0029\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0029\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0028\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0026\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0026\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0025\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0025\n",
      "koniec uczenia\n"
     ]
    }
   ],
   "source": [
    "print('rozpoczecie uczenia')\n",
    "#ustaw verbose=0 aby wyłączyć szczegóły \n",
    "hist = mlp.fit(data_x, data_y, epochs=300, verbose=1, batch_size=4)  #  parametry patrz dokumentacja\n",
    "print('koniec uczenia')\n",
    "# ponowne wykonanie powoduje douczanie a nie uczenie od nowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfawIIuicule"
   },
   "source": [
    "Sprawdzenie czego model się nauczył:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBFKnSPoIfdY",
    "outputId": "aefcdf4a-c1c3-4bb6-f6e8-60c155792191"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05376461]\n",
      " [0.95494664]\n",
      " [0.9548219 ]\n",
      " [0.05354601]]\n"
     ]
    }
   ],
   "source": [
    "pred = mlp.predict(data_x)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7W2VVjPcydZ"
   },
   "source": [
    "## Zagadnienie niedouczenia lub przeuczenia sieci\n",
    "Przykładowy problem aproksymacji funkcji.\n",
    "\n",
    "### Zwróć uwagę\n",
    "- W rzeczywistości dane często pochodzą z pomiarów, które obarczone są niepewnością. W poniższym przykładzie modelujemy to poprzez dodanie losowego błędu do wartości funkcji sinus. \n",
    "\n",
    "- Funkcja sinus pełni tu rolę rzeczywistego modelu, którego w praktycznych problemach tak naprawdę nie znamy. Próbujemy go odkryć/aproksymować na podstawie dostępnych nam danych. \n",
    "\n",
    "- Celem nauki jest osiągnięcie dobrej generalizacji. Tutaj oznacza to, że sieć, na podstawie dostępnych (zaszumionych) przykładów, powinna nauczyć się prawidłowego przebiegu funkcji sinus. \n",
    "\n",
    "- Jeśli będziemy uczyć sieć zbyt długo, może pojawić się niekorzystny efekt zwany przeuczeniem. Ma to miejsce gdy sieć po odkryciu głównych zależności/ogólnego przebiegu funkcji, zaczyna dostosowywać się do szumu istniejącego w danych. Można temu przeciwdziałać poprzez odpowiednio wczesne zatrzymanie procesu uczenia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ng3Wi7DhJF6X"
   },
   "source": [
    "### Dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "2DyVhmVXJGM9",
    "outputId": "eb004e2b-534e-415d-ee54-bfaf7517f4fa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATx0lEQVR4nO3df4xl5V3H8c/HhZZpTTrgbig7bNg1blapG90ygdZJDAGahdqwm22tYDTU0GC12GrMmkWTtjYxOwajrYHUrEhZtIEaINutoKhMDaa2hLssLb8kXZEfe1m6U37VmrX88Osfc0dmhnvvzJ177vnxPO9XMtl7zz3c81xmzvc+5/t8z/M4IgQASN+PVN0AAEA5CPgAkAkCPgBkgoAPAJkg4ANAJk6qugG9rF27NjZu3Fh1MwCgUQ4dOvS9iFjX7bXaBvyNGzeq1WpV3QwAaBTbT/V6jZQOAGSikIBv+0bbx20/3OP1822/bPvBzs+nijguAGDlikrp3CTpOkk399nnXyPiAwUdDwAwoEJ6+BFxr6QXingvAMBolJnDf6/tb9n+e9vv6raD7atst2y3ZmdnS2waAKSvrCqdBySdFRE/sP1+SQckbV66U0Tsk7RPkiYnJ5nVDUjcgcNtXXv343r2pRNaPz6m3du3aOe2iaqblaxSevgR8f2I+EHn8V2STra9toxjA6inA4fbuuaOh9R+6YRCUvulE7rmjod04HC76qYlq5SAb/udtt15fG7nuM+XcWwA9XTt3Y/rxKuvL9p24tXXde3dj1fUovQVktKxfYuk8yWttX1U0qclnSxJEfEXkj4k6TdsvybphKTLgon4gaw9+9KJgbZjeIUE/Ii4fJnXr9Nc2SYASJLWj4+p3SW4rx8fq6A1eeBOWwCV2L19i8ZOXrNo29jJa7R7+5aKWpS+2s6lAyBt89U4VOmUh4DfMJSxISU7t03w91siAn4N9Qrq82Vs85UN82VskjhpUFt0UuqDgF8z/YJ6vzI2TiDUEZ2UemHQtmb6BXXK2NA01NrXCwG/ZvoF9V7lapSxoa7opNQLAb9m+gV1ytjQNEV3Ug4cbmtqekab9typqekZpmEYEAG/ZvoF9Z3bJrR311ZNjI/JkibGx7R311ZyoaitIjspzL0zPAZtK9SveqHXdsrY0CRF1tpTtDA8An5Flqte4A8YqSjq75nxgOGR0qlI0dUL5DaROooWhkfAr0iRvRVym8gBRQvDI+BXpMjeCrXOyAFFC8Mjh1+R3du3LMrhS6vvrZDbRC4Y3xoOPfyKFNlbIbcJYCXo4VeoqN5KkVcLANJFwE8A84oDWAkCfiLIbQJYDgF/FZjfG0ATEfAHxPzeAJqKKp0BUfMOoKkI+AOi5h1AU5HSGdD68TG1uwR3at6B6jCutjL08AfEfB5AvTCX1MoR8AfEfB5AvTCutnKkdFaBmnegPhhXWzl6+AAajbmkVo4efg8MAgGDqeqcYS6plSPgd7Ham6v4kkCuir4hcZBzibmkVs4RUXUbupqcnIxWq1XJsaemZ7qWXk6Mj+nrey7o+t8s/YOX5noZDOgiB6s5Z3rhXBqO7UMRMdntNXL4XaxmEIhKAeSsyIFTzqXRIaXTxWpurqJSADkr8obEss6lHFOw9PC7WM3NVVQKIGdF3pBY9Ll04HBbU9Mz2rTnTk1Nz+jA4Xa2N2sVEvBt32j7uO2He7xu239u+4jtb9t+dxHHHZXV3FzFHbjIWZE3JBZ5LvUK7H/41UeyTBsVldK5SdJ1km7u8folkjZ3fs6T9IXOv7U16M1VVAogd0XdkFjkudRrPGDptnmpp2ALCfgRca/tjX122SHp5pgrCfqm7XHbZ0TEsSKOXxe9/uBzzBUCwyjqy2PQAJ56CrasHP6EpGcWPD/a2baI7atst2y3ZmdnS2raaOWaKwTqoFcAHx87OcsUbK0GbSNiX0RMRsTkunXrqm5OISgxA6rTazzgM5e+K8tJEMsqy2xL2rDg+ZmdbcmjXBOoznLjAakH+KXKCvgHJV1t+1bNDda+nFr+vhcWTAGqxey2byiqLPMWSd+QtMX2UdtX2v6Y7Y91drlL0hOSjkj6S0m/WcRxm4ByTQB1UVSVzuXLvB6SPl7EsZqm6nJNKoSAwaR8zjC1QgmquqQsegZDIHWpnzO1qtJBsagQAgaT+jlDwE8YFULAYFI/Zwj4CWNCN2AwqZ8zBPyEUSEEDCb1c4ZB24RVXSEENE3q5wxLHAJAQljiEABASgfAYFK+MSl1BHwAK5b6jUmpyz7g01sBVq7fjUmcN/WXdcDPubeymi86vhyR+o1Jqct60Db126h7Wc0qXKzcBSn9G5NSl3XAz7W3spovuly/HLFY6jcmpS7rgJ9rb2U1X3S5fjlisZ3bJrJcGjAVWefwd2/fsiiHL+XRW1nNKlys3IV5rCDVXFn38HPtrazmspxLeaD5su7hS3n2VlYzX0jqc4zkrFf1FVVZ6WEuHSBjS0uTpbkrtw+eM6HbD7XftD2HK+CmYy4dAF31qr665b5nqMpKEAEfyFivKqvXe1z5U5XVbAR8IGO9qqzW2APtj2Yg4AMZ61V9dfl5G6jKSlD2VTpAzvpVX02edRpVOomhSgcAEkKVDgCAgA8AuSDgA0Amshm05TZxALnLIuDnvLIVAMzLIqXD4h0AkEkPn8U7AAwrhbRwFj38XFe2AlCMVNZ0ziLgs3gHgGGkkhYuJODbvtj247aP2N7T5fWP2J61/WDn56NFHHelcl3ZajUOHG5ranpGm/bcqanpmcb1YIBRSCUtPHQO3/YaSddLep+ko5Lut30wIh5dsuuXI+LqYY+3WjmubDUoqpmA7lJZ07mIHv65ko5ExBMR8YqkWyXtKOB9UbJULluBoqWSFi4i4E9IembB86OdbUt90Pa3bd9me0O3N7J9le2W7dbs7GwBTcMgUrlsBYqWSlq4rLLMr0q6JSJ+aPvXJe2XdMHSnSJin6R90txsmSW1DR2pXLYCo5BCWriIHn5b0sIe+5mdbf8vIp6PiB92nt4g6ZwCjouCpXLZCqC7IgL+/ZI2295k+y2SLpN0cOEOts9Y8PRSSY8VcFwULJXLVgDdDZ3SiYjXbF8t6W5JayTdGBGP2P6spFZEHJT0CduXSnpN0guSPjLscTEaKVy2AuiOFa8AICGseAUAyGPyNAAYlSZNqkbAB4BVatrd6ckF/CZ926aO3wVS1+/u9Dr+rScV8Jv2bZsyfhfIQdPuTk9q0Ja5YOqD3wVy0LS1NpIK+E37tk0Zv4t6Ydrr0Wja3elJBfymfdumjN9FfaSyWlMdNe3u9KRy+Lu3b1mUN5bq/W2bMn4X9dG0gcWmadLd6UkF/Pn/6VSGVI/fRX2QXqtO3SrVkgr4UrO+bVPH76IemPa6GnWsVEsqhw/gzZo2sJiKOlaqJdfDB7AY6bVq1DGVRsAHMkB6rXx1TKWR0gGAEahjKo0ePgCMQB1TaQR8ABiRuqXSSOkAQCYI+ACQCQI+AGSCgA8AmSDgA0AmCPgAkAnKMoEGqtssjGgGAj7QMHWchRHNQMAHGoYFTZqvqis0Aj7QMHWchRErV+UVGoO2GBoLZJeL9YKbrcp58gn4GAoLZJevjrMwYuWqvEIj4GModVzVJ3U7t01o766tmhgfkyVNjI9p766t2rltgqutBqjyCo0cPoZCPrka3WZhpHqnGXZv37Lo9ySVd4VGDx9DIZ9cH1xtNUO/K7RRo4ePoVTZW8FiXG01R1Xz5NPDx1Cq7K1gMa62sJxCevi2L5b0eUlrJN0QEdNLXn+rpJslnSPpeUm/FBFPFnFsVG/Q3grTAowGV1tYztA9fNtrJF0v6RJJZ0u63PbZS3a7UtKLEfETkv5M0h8Pe1w0E2Wco8PVFpZTRA//XElHIuIJSbJ9q6Qdkh5dsM8OSZ/pPL5N0nW2HRFRwPHRIEwLMFp1W0MV9VJEDn9C0jMLnh/tbOu6T0S8JullST+29I1sX2W7Zbs1OztbQNNQNwwsAtWp1aBtROyLiMmImFy3bl3VzcEIMLAIVKeIlE5b0oYFz8/sbOu2z1HbJ0l6h+YGb5EZBha76zWQzQA3ilREwL9f0mbbmzQX2C+T9MtL9jko6QpJ35D0IUkz5O/zNB+sCGJv6HWHbOupF3T7oTZ3zqIwLiLu2n6/pM9prizzxoj4I9ufldSKiIO2T5H015K2SXpB0mXzg7y9TE5ORqvVGrptQN1NTc+o3WUMY42t17ucnxPjY/r6ngvKaBoayPahiJjs9lohdfgRcZeku5Zs+9SCx/8j6ReLOBaQml4D1t2Cfb/9geXUatAWyFGvAes19kD7A8sh4AMV6zW//eXnbWDeexSKydOAivUbyJ486zQGuFGYQgZtR4FBWwAYXL9BW1I6AJAJAj4AZIIcPgDUxKjvrCbgA0ANlLEmMSkdAKiBMtYkJuADQA2UMXU4AR8AaqCMqcMJ+ABQA73uuC7yzmoGbQGgBsqYOpyADwA1Meo1iUnpAEAmCPgAkAkCPgBkgoAPAJkg4ANAJgj4AJAJAj4AZII6fDTaqKeTBVJCwEdjlTGdLJASUjporDKmkwVSQsBHY5UxnSyQEgI+GquM6WSBlBDw0VhlTCcLpIRBWzRWv+lkqd4B3oyAj0brNp0s1TtAd6R0kByqd4DuCPhIDtU7QHekdFAbReXd14+Pqd0luFO9g9zRw0ctzOfd2y+dUOiNvPuBw+2B34vqHaA7Aj5qoci8+85tE9q7a6smxsdkSRPjY9q7aysDtsjeUCkd26dJ+rKkjZKelPThiHixy36vS3qo8/TpiLh0mOMiPUXn3Ue9GDTQRMP28PdIuiciNku6p/O8mxMR8bOdH4I93oS7ZoHRGzbg75C0v/N4v6SdQ74fMkXeHRi9YQP+6RFxrPP4OUmn99jvFNst29+03fNLwfZVnf1as7OzQzYNTULeHRg9R0T/Hex/lvTOLi/9gaT9ETG+YN8XI+LULu8xERFt2z8uaUbShRHxH/2OOzk5Ga1WayWfAQDQYftQREx2e23ZQduIuKjPG3/X9hkRccz2GZKO93iPduffJ2z/i6RtkvoGfABAsYZN6RyUdEXn8RWSvrJ0B9un2n5r5/FaSVOSHh3yuACAAQ0b8Kclvc/2dyRd1Hku25O2b+js81OSWra/JelrkqYjgoAPACUbqg4/Ip6XdGGX7S1JH+08/jdJW4c5DgBgeNxpCwCZIOADQCYI+ACQCaZHBkrCsouoGgEfKAHLLqIOCPhohKb3jvtN/9ykz4FmI+Cj9lLoHbPsIuqAQVvUXgqLkjP9M+qAgI/aq2vv+MDhtqamZ7Rpz52amp7puxwj0z+jDkjpoPbquCj5oGmm+W1NHodA8xHwUXu7t29ZFFyl0fSOBxkYXs0gLMsuomoEfNReGb3jQXvsdU0zAf0Q8NEIo+4dD9pjr2OaCVgOg7aABu+xMwiLJqKHj6z0ytMP2mPvl2Zq+k1iSNeya9pWhTVtUbSleXpprle+d9fccg29XhskWPc7BkEfZei3pi0pHWRjuTz93l1bNTE+JkuaGB9bVZBO4SYxpIuUDrKxXJ6+iIFhqndQZ/TwkY0ypjdgCgXUGQEf2SijsobqHdQZKR1ko4wbuJhCAXVGlQ6wDMos0ST9qnTo4QN9pDAXPzCPHD7QB2WWSAkBH+iDMkukhIAP9EGZJVJCwAf6oMwSKWHQFuiDMkukhIAPLIOVqpAKUjoAkAkCPgBkgoAPAJkg4ANAJgj4AJCJ2k6eZntW0lNDvMVaSd8rqDlNkdtnzu3zSnzmXAzzmc+KiHXdXqhtwB+W7VavGeNSldtnzu3zSnzmXIzqM5PSAYBMEPABIBMpB/x9VTegArl95tw+r8RnzsVIPnOyOXwAwGIp9/ABAAsQ8AEgE8kFfNsX237c9hHbe6puz6jZ3mD7a7Yftf2I7U9W3aay2F5j+7Dtv6u6LWWwPW77Ntv/bvsx2++tuk2jZvt3On/XD9u+xfYpVbepaLZvtH3c9sMLtp1m+59sf6fz76lFHCupgG97jaTrJV0i6WxJl9s+u9pWjdxrkn43Is6W9B5JH8/gM8/7pKTHqm5EiT4v6R8i4icl/YwS/+y2JyR9QtJkRPy0pDWSLqu2VSNxk6SLl2zbI+meiNgs6Z7O86ElFfAlnSvpSEQ8ERGvSLpV0o6K2zRSEXEsIh7oPP4vzQWB5Cdvt32mpF+QdEPVbSmD7XdI+nlJfyVJEfFKRLxUbatKcZKkMdsnSXqbpGcrbk/hIuJeSS8s2bxD0v7O4/2SdhZxrNQC/oSkZxY8P6oMgt882xslbZN0X7UtKcXnJP2epP+tuiEl2SRpVtIXO2msG2y/vepGjVJEtCX9iaSnJR2T9HJE/GO1rSrN6RFxrPP4OUmnF/GmqQX8bNn+UUm3S/rtiPh+1e0ZJdsfkHQ8Ig5V3ZYSnSTp3ZK+EBHbJP23CrrMr6tO3nqH5r7s1kt6u+1fqbZV5Yu52vlC6udTC/htSRsWPD+zsy1ptk/WXLD/UkTcUXV7SjAl6VLbT2oubXeB7b+ptkkjd1TS0YiYv3q7TXNfACm7SNJ/RsRsRLwq6Q5JP1dxm8ryXdtnSFLn3+NFvGlqAf9+SZttb7L9Fs0N8BysuE0jZduay+s+FhF/WnV7yhAR10TEmRGxUXO/45mISLrnFxHPSXrG9pbOpgslPVphk8rwtKT32H5b5+/8QiU+UL3AQUlXdB5fIekrRbxpUouYR8Rrtq+WdLfmRvRvjIhHKm7WqE1J+lVJD9l+sLPt9yPirgrbhNH4LUlf6nRmnpD0axW3Z6Qi4j7bt0l6QHPVaIeV4DQLtm+RdL6ktbaPSvq0pGlJf2v7Ss1NE//hQo7F1AoAkIfUUjoAgB4I+ACQCQI+AGSCgA8AmSDgA0AmCPgAkAkCPgBk4v8AUPCD0KZXU38AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data_x = np.linspace(0, 10, 50)\n",
    "data_y = np.sin(data_x) + np.random.random(data_x.shape[0])*0.5\n",
    "fig = plt.figure()\n",
    "plt.plot(data_x, data_y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSlJjI08JOv-"
   },
   "source": [
    "### Podział na dane uczące i walidacyjne\n",
    "\n",
    "Dane walidacyjne służą do monitorowania procesu uczenia, sprawdzania jak sieć radzi sobie z danymi, które nie są wykorzystywane do modyfikacji wag.\n",
    "\n",
    "Jeśli błąd na danych uczących maleje, a na danych walidacyjnych już nie (lub wręcz rośnie), jest to potencjalny sygnał, że sieć jest przeczuczona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "dJ3LaqvzJPyt",
    "outputId": "3c417884-6cc0-4219-f102-42c52cf9b770"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = np.arange(50)\n",
    "np.random.shuffle(temp)\n",
    "val_x = data_x[temp[35:]]\n",
    "val_y = data_y[temp[35:]]\n",
    "data_x = data_x[temp[:35]]\n",
    "data_y = data_y[temp[:35]]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(data_x, data_y, 'bo', label='uczace')\n",
    "plt.plot(val_x, val_y, 'ro', label='validacyjne')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyRXFhcGJaJ9"
   },
   "source": [
    "### Model sieci MLP\n",
    "Mała sieć, 35 neuronów w warstwie ukrytej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aEGOb2bSJag9",
    "outputId": "49751bb6-8782-4aff-cfb1-81613912e00a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                70        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 36        \n",
      "=================================================================\n",
      "Total params: 106\n",
      "Trainable params: 106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "x = Input(shape=(1,))\n",
    "h = Dense(35, input_dim=1, use_bias=True, activation='tanh', kernel_initializer='random_uniform', bias_initializer='random_uniform')(x)\n",
    "y = Dense(1, use_bias=True, activation='linear', kernel_initializer='random_uniform', bias_initializer='random_uniform')(h)\n",
    "model1 = Model(inputs=x, outputs=y)\n",
    "rms = tf.keras.optimizers.RMSprop(lr=0.001)\n",
    "model1.compile(loss='mse', optimizer=rms)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6p0BWO7KKLe"
   },
   "source": [
    "### Wizualizacja uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "VX5AYvr8KIwC",
    "outputId": "58956db0-a26c-4ce5-cbd9-11e646333fab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img class=\"myimage\" src=\"data:image/png;base64,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\"></img>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "import time\n",
    "import base64\n",
    "import IPython\n",
    "\n",
    "def fig2b64(f):\n",
    "  data = io.BytesIO()\n",
    "  f.savefig(data, format='png')\n",
    "  data.seek(0)\n",
    "  return base64.b64encode(data.read()).decode()\n",
    "\n",
    "data_xx = np.linspace(0, 10, 100)\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "model = model1\n",
    "n_epochs = 300\n",
    "\n",
    "hist = model.fit(data_x, data_y, epochs=10, verbose=0, batch_size=35, validation_data=(val_x, val_y))\n",
    "train_loss.append(model.evaluate(data_x, data_y, verbose=0))\n",
    "val_loss.append(model.evaluate(val_x, val_y, verbose=0))\n",
    "pred = model.predict(data_xx)\n",
    "ax1.plot(data_x, data_y, 'bo', label='uczace')\n",
    "ax1.plot(val_x, val_y, 'ro', label='walidacyjne')\n",
    "ax1.plot(data_xx, pred, 'k-', label='MLP')\n",
    "ax1.legend()\n",
    "ax2.plot(train_loss, label='train_loss')\n",
    "ax2.plot(val_loss, label='val_loss')\n",
    "ax2.legend()\n",
    "data_str = fig2b64(fig)\n",
    "rys = IPython.display.display_html(f'<img class=\"myimage\" src=\"data:image/png;base64,{data_str}\"></img>', raw=True)\n",
    "\n",
    "for i in range(n_epochs):\n",
    "  IPython.display.clear_output(wait=True)\n",
    "  #time.sleep(0.2)\n",
    "  hist = model.fit(data_x, data_y, epochs=10, verbose=0, batch_size=35, validation_data=(val_x, val_y))\n",
    "  train_loss.append(model.evaluate(data_x, data_y, verbose=0))\n",
    "  val_loss.append(model.evaluate(val_x, val_y, verbose=0))\n",
    "  pred = model.predict(data_xx)\n",
    "  ax1.clear()\n",
    "  ax2.clear()\n",
    "  ax1.plot(data_x, data_y, 'bo', label='uczace')\n",
    "  ax1.plot(val_x, val_y, 'ro', label='walidacyjne')\n",
    "  ax1.plot(data_xx, pred, 'k-', label='MLP')\n",
    "  ax1.legend()\n",
    "  ax2.plot(train_loss, label='train_loss')\n",
    "  ax2.plot(val_loss, label='val_loss')\n",
    "  ax2.legend()\n",
    "  data_str = fig2b64(fig)\n",
    "  rys = IPython.display.display_html(f'<img class=\"myimage\" src=\"data:image/png;base64,{data_str}\"></img>', raw=True)\n",
    "plt.close(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4oFRUxEQd4y"
   },
   "source": [
    "### Model sieci MLP\n",
    "\n",
    "\n",
    "Większa sieć, dwie warstwy ukryte odpowiednio 100 i 50 neuronów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bOAJBh_1QswD",
    "outputId": "91d458eb-a428-4571-cf46-c436a2046f0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               200       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 5,301\n",
      "Trainable params: 5,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "x = Input(shape=(1,))\n",
    "h1 = Dense(100, input_dim=1, use_bias=True, activation='tanh', kernel_initializer='random_uniform', bias_initializer='random_uniform')(x)\n",
    "h2 = Dense(50, input_dim=1, use_bias=True, activation='tanh', kernel_initializer='random_uniform', bias_initializer='random_uniform')(h1)\n",
    "y = Dense(1, use_bias=True, activation='linear', kernel_initializer='random_uniform', bias_initializer='random_uniform')(h2)\n",
    "model2 = Model(inputs=x, outputs=y)\n",
    "rms = tf.keras.optimizers.RMSprop(lr=0.001)\n",
    "model2.compile(loss='mse', optimizer=rms)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Daz5x7J-RBTi"
   },
   "source": [
    "### Wizualizacja uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "PHESSJH6REQi",
    "outputId": "808250c9-fa9a-4ee7-cc80-9b06387a4f3a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img class=\"myimage\" src=\"data:image/png;base64,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\"></img>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_xx = np.linspace(0, 10, 100)\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "model = model2\n",
    "n_epochs = 400\n",
    "\n",
    "hist = model.fit(data_x, data_y, epochs=10, verbose=0, batch_size=35, validation_data=(val_x, val_y))\n",
    "train_loss.append(model.evaluate(data_x, data_y, verbose=0))\n",
    "val_loss.append(model.evaluate(val_x, val_y, verbose=0))\n",
    "pred = model.predict(data_xx)\n",
    "ax1.plot(data_x, data_y, 'bo', label='uczace')\n",
    "ax1.plot(val_x, val_y, 'ro', label='walidacyjne')\n",
    "ax1.plot(data_xx, pred, 'k-', label='MLP')\n",
    "ax1.legend()\n",
    "ax2.plot(train_loss, label='train_loss')\n",
    "ax2.plot(val_loss, label='val_loss')\n",
    "ax2.legend()\n",
    "data_str = fig2b64(fig)\n",
    "rys = IPython.display.display_html(f'<img class=\"myimage\" src=\"data:image/png;base64,{data_str}\"></img>', raw=True)\n",
    "\n",
    "for i in range(n_epochs):\n",
    "  IPython.display.clear_output(wait=True)\n",
    "  #time.sleep(0.2)\n",
    "  hist = model.fit(data_x, data_y, epochs=10, verbose=0, batch_size=35, validation_data=(val_x, val_y))\n",
    "  train_loss.append(model.evaluate(data_x, data_y, verbose=0))\n",
    "  val_loss.append(model.evaluate(val_x, val_y, verbose=0))\n",
    "  pred = model.predict(data_xx)\n",
    "  ax1.clear()\n",
    "  ax2.clear()\n",
    "  ax1.plot(data_x, data_y, 'bo', label='uczace')\n",
    "  ax1.plot(val_x, val_y, 'ro', label='walidacyjne')\n",
    "  ax1.plot(data_xx, pred, 'k-', label='MLP')\n",
    "  ax1.legend()\n",
    "  ax2.plot(train_loss, label='train_loss')\n",
    "  ax2.plot(val_loss, label='val_loss')\n",
    "  ax2.legend()\n",
    "  data_str = fig2b64(fig)\n",
    "  rys = IPython.display.display_html(f'<img class=\"myimage\" src=\"data:image/png;base64,{data_str}\"></img>', raw=True)\n",
    "plt.close(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmlFuDB6Rg_Y"
   },
   "source": [
    "## Kiedy zakończyć uczenie?\n",
    "Jednym z kluczowych aspektów (poza doborem architektury) jest zdecydowanie kiedy zakończyć uczenie sieci neuronowej. Najpopularniejsza technika polega na obserwacji wartości błedów osiąganych na zbiorze uczącym i zbiorze walidacyjnym. Gdy błąd na zbiorze walidacyjnym przestaje maleć (zazwyczaj zaczyna rosnąć) to znaczy, że sieć zaczyna się przeuczać (traci swoje zdalonośći generalizacyjne) i wtedy należy zakończyć proces uczenia. Taka strategia nazywa się strategią wczesnego zatrzymania (_early stopping_)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhcfIhTsRpYT"
   },
   "source": [
    "## Problemy klasyfikacyjne z wieloma klasami\n",
    "\n",
    "Baza danych irysów zawiera przykłady z trzech klas. Zwróć uwagę na odpowiednie zakodowanie informacji o etykietach klas dla przykładów za pomocą funkcji `keras.utils.to_categorical`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2TmG_WORvTq",
    "outputId": "9728729e-a11e-4256-98f3-12556b5787e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'filename', 'target', 'target_names']\n",
      "<class 'numpy.ndarray'>\n",
      "(150, 4)\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'>\n",
      "(150, 3)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "iris_db = datasets.load_iris()\n",
    "print(dir(iris_db))\n",
    "print(type(iris_db.data)) #dane jako macierz numpy\n",
    "print(iris_db.data.shape) #kazdy przyklad w wierszu\n",
    "print(iris_db.feature_names) #nazwy atrybutow (sygnaly wejsciowe sieci)\n",
    "print(iris_db.data[:10,:]) #podglad\n",
    "print(iris_db.target_names) #nazwy trzech klas\n",
    "print(iris_db.target) #etykiety klas zakodowane numerycznie jako 0, 1, 2\n",
    "\n",
    "#d: zakodowane etykiety klas w sposob umozliwiajacy uczenie sieci\n",
    "d = tf.keras.utils.to_categorical(iris_db.target, num_classes=3)\n",
    "print(type(d))\n",
    "print(d.shape)\n",
    "print(d[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CedtfcoSBKP"
   },
   "source": [
    "### Warstwa wyjściowa softmax\n",
    "\n",
    "W warstwie wyjściowej softmax, każdy neuron realizuje sumę ważoną dochodzących do niego sygnałów wejściowych. Następnie, odpowiedzi wszystkich neuronów wyjściowych są przetwarzane zgodnie ze wzorem\n",
    "\n",
    "$$P(y=j|\\bf{x})=\\frac{e^{\\bf{x}^{T}\\bf{w}_j}}{\\sum_{k=1}^{K}{e^{\\bf{x}^{T}\\bf{w}_k}}}$$\n",
    "\n",
    "gdzie $K$ to liczba neuronów wyjściowych (liczba klas w problemie klasyfikacyjnym), $w_j$ to wagi j-tego neuronu wyjściowego, $x$ to sygnały wejściowe neuronów z warstwy wyjściowej (odpowiedzi poprzedniej warstwy).\n",
    "\n",
    "Wartości te mogą być interpretowane jako prawdopodobieństwa przynależności danego przykładu (podanego na wejście sieci) do danej klasy, którą reprezentuje j-ty neuron wyjściowy.\n",
    "\n",
    "Dla takiej warstwy wyjściowej, funkcją straty używaną w trakcie uczenia jest zazwyczaj `categorical_entropy`, która mierzy podobieństwo dwóch rozkładów prawdopodobieństwa przynależności danych trenujących do klas: rzeczywisty (na podstawie zbioru trenującego) oraz ten realizowany przez sieć."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEDFaGMlTAcW"
   },
   "source": [
    "### Zapis i odczyt modelu do/z pliku\n",
    "\n",
    "W poniższym przykładzie zwróć uwagę na zapis modelu do pliku i jego ponowne wczytanie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fHS7Ae4TEUa",
    "outputId": "2d77167d-5f38-428b-8a2c-9f15a77d202e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9084 - accuracy: 0.5400\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5474 - accuracy: 0.7267\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8467\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3782 - accuracy: 0.8400\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.9467\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.9133\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.9600\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.9267\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2038 - accuracy: 0.9333\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.9600\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1483 - accuracy: 0.9667\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9667\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.9733\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 0.9667\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1210 - accuracy: 0.9733\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1343 - accuracy: 0.9533\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1095 - accuracy: 0.9600\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1211 - accuracy: 0.9600\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9600\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.9200\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 0.9600\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1082 - accuracy: 0.9600\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.9667\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.9533\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 0.9800\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 0.9800\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0872 - accuracy: 0.9800\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.9600\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1008 - accuracy: 0.9800\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0807 - accuracy: 0.9733\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.9467\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 0.9667\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.9667\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9600\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9533\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0843 - accuracy: 0.9667\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0693 - accuracy: 0.9867\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.9667\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.9667\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.9733\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.9533\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9733\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0678 - accuracy: 0.9867\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1039 - accuracy: 0.9600\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1076 - accuracy: 0.9667\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9733\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.9800\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0808 - accuracy: 0.9800\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9667\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9733\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0908 - accuracy: 0.9800\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.9800\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0856 - accuracy: 0.9667\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0787 - accuracy: 0.9800\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1023 - accuracy: 0.9600\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0723 - accuracy: 0.9733\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9600\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9667\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1011 - accuracy: 0.9467\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.9733\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0889 - accuracy: 0.9667\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9600\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9533\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0792 - accuracy: 0.9667\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9533\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0792 - accuracy: 0.9667\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9733\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1234 - accuracy: 0.9533\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.9667\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0860 - accuracy: 0.9667\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9733\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9600\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0856 - accuracy: 0.9733\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9800\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1010 - accuracy: 0.9533\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0993 - accuracy: 0.9667\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.9667\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0765 - accuracy: 0.9600\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9733\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9533\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0819 - accuracy: 0.9733\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0797 - accuracy: 0.9733\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0873 - accuracy: 0.9733\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.9800\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9667\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.9733\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9600\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9600\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9733\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0866 - accuracy: 0.9667\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9667\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9733\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 0.9733\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0975 - accuracy: 0.9600\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0777 - accuracy: 0.9667\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0678 - accuracy: 0.9800\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1126 - accuracy: 0.9600\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.9467\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9667\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9733\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9733\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9733\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.9800\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9667\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.9733\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.9667\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0622 - accuracy: 0.9867\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.9733\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9800\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 0.9867\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9600\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0830 - accuracy: 0.9600\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.9733\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 0.9600\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 0.9867\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9867\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9667\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9667\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0820 - accuracy: 0.9733\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0728 - accuracy: 0.9667\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9800\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0774 - accuracy: 0.9600\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0860 - accuracy: 0.9600\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0621 - accuracy: 0.9667\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9733\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9800\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9800\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9533\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9600\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9800\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9667\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9667\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9800\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9533\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.9667\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9800\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9667\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.9733\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 0.9733\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0568 - accuracy: 0.9867\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9733\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9800\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.9733\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9733\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0746 - accuracy: 0.9667\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0766 - accuracy: 0.9600\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9733\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9667\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0782 - accuracy: 0.9667\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9667\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.9800\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.9733\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0643 - accuracy: 0.9867\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9800\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9800\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9733\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9733\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.9733\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.9533\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.9600\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.9800\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0811 - accuracy: 0.9533\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.9667\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.9733\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0786 - accuracy: 0.9667\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9733\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.9667\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.9800\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0632 - accuracy: 0.9800\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 0.9600\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9733\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 0.9800\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9467\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 0.9533\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9800\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9667\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9800\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9667\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0699 - accuracy: 0.9800\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9800\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9800\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9667\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.9733\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9600\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9800\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9733\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9733\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.9667\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9800\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9733\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9733\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.9733\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9733\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0753 - accuracy: 0.9667\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0844 - accuracy: 0.9667\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9800\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9733\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0646 - accuracy: 0.9800\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9800\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9800\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9867\n",
      "model koncowy: [0.05204842984676361, 0.9866666793823242]\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9867\n",
      "model z pliku: [0.05204842984676361, 0.9866666793823242]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='tanh', input_dim=4))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(iris_db.data, d,\n",
    "          epochs=200,\n",
    "          batch_size=10)\n",
    "\n",
    "score = model.evaluate(iris_db.data, d, batch_size=10)\n",
    "print('model koncowy:',score)\n",
    "\n",
    "#sprawdzenie czy dziala zapis/odczyt modelu z pliku\n",
    "model.save('my_model.h5')\n",
    "from tensorflow.keras.models import load_model\n",
    "model2 = load_model('my_model.h5')\n",
    "score2 = model2.evaluate(iris_db.data, d, batch_size=10)\n",
    "print('model z pliku:',score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xPZCNLQ2zKO"
   },
   "source": [
    "## Zadanie 1 (10 pkt., obowiązkowe)\n",
    "Naucz sieć diagnozować cukrzycę.\n",
    "\n",
    "- Wykorzytaj dane z pliku `pima-indians-diabetes.data.csv`. Dane są również dostępne w `sklearn`. Zaimportuje je jako `diab_db=datasets.load_diabetes()`\n",
    "\n",
    "- Podziel dostępne dane losowo na dane uczące i testowe (walidacyjne) w proporcji 70% / 30%. Podział danych jest wykonywany raz i jest używany niezmieniony w dalszych obliczeniach dla wszystkich sieci.\n",
    "\n",
    "- Dobierz jak najlepsze parametry uczenia oraz architektury sieci z jedną oraz z dwiema warstwami ukrytymi (po jednej na każdy rodzaj). Jakość działania sieci oceniamy na podstawie jej wyników na danych testowych. Postaraj się w odpowiednim momencie zatrzymać proces uczenia.\n",
    "\n",
    "- Czy sieć z dwiema warstwami ukrytymi działa lepiej niż sieć z jedną warstwą ukrytą? Porównania i wnioski przedstaw na podstawie uśrednionych wyników dziesięciu sieci każdego rodzaju (tzn. najpierw ustal architekturę sieci, następnie przeprowadź 10 procesów trenownia, startując za każdym razem z losowych początkowych wag). \n",
    "\n",
    "- W dostarczonym kodzie umieść proces uczenia i testowania wybranych architektur sieci.\n",
    "\n",
    "__Uwaga:__ Przy uczeniu większych modeli warto wykonywać obliczenia z wykorzystaniem karty graficznej. Aby uruchomić notatnik z wykorzystaniem GPU należy wejść do Edit->Notebook settings i zmienić Hardware accelerator na GPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0x4ifsSuTYxo"
   },
   "source": [
    "TWÓJ KOD TUTAJ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t8A_3O1Dehmr",
    "outputId": "db10207b-80ea-471d-8d25-bab7e2ee5a8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "31/31 [==============================] - 1s 12ms/step - loss: 0.2378 - accuracy: 0.6084 - val_loss: 0.2158 - val_accuracy: 0.6754\n",
      "Epoch 2/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2311 - accuracy: 0.6149 - val_loss: 0.2172 - val_accuracy: 0.6754\n",
      "Epoch 3/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2277 - accuracy: 0.6117 - val_loss: 0.2140 - val_accuracy: 0.6819\n",
      "Epoch 4/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2220 - accuracy: 0.6375 - val_loss: 0.2107 - val_accuracy: 0.6732\n",
      "Epoch 5/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2232 - accuracy: 0.6311 - val_loss: 0.2096 - val_accuracy: 0.6841\n",
      "Epoch 6/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2199 - accuracy: 0.6408 - val_loss: 0.2133 - val_accuracy: 0.6972\n",
      "Epoch 7/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2180 - accuracy: 0.6667 - val_loss: 0.2044 - val_accuracy: 0.6841\n",
      "Epoch 8/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.6472 - val_loss: 0.2039 - val_accuracy: 0.6950\n",
      "Epoch 9/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2148 - accuracy: 0.6537 - val_loss: 0.2039 - val_accuracy: 0.6776\n",
      "Epoch 10/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2133 - accuracy: 0.6570 - val_loss: 0.2046 - val_accuracy: 0.6797\n",
      "Epoch 11/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2150 - accuracy: 0.6537 - val_loss: 0.2042 - val_accuracy: 0.7015\n",
      "Epoch 12/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2089 - accuracy: 0.6828 - val_loss: 0.1986 - val_accuracy: 0.7146\n",
      "Epoch 13/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2096 - accuracy: 0.6893 - val_loss: 0.1978 - val_accuracy: 0.7059\n",
      "Epoch 14/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.6699 - val_loss: 0.2025 - val_accuracy: 0.7015\n",
      "Epoch 15/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.6828 - val_loss: 0.2008 - val_accuracy: 0.7037\n",
      "Epoch 16/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2058 - accuracy: 0.6828 - val_loss: 0.2180 - val_accuracy: 0.6340\n",
      "Epoch 17/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2086 - accuracy: 0.6634 - val_loss: 0.2006 - val_accuracy: 0.7081\n",
      "Epoch 18/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2060 - accuracy: 0.6796 - val_loss: 0.1929 - val_accuracy: 0.7124\n",
      "Epoch 19/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2060 - accuracy: 0.6828 - val_loss: 0.1944 - val_accuracy: 0.7190\n",
      "Epoch 20/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.6472 - val_loss: 0.1991 - val_accuracy: 0.7015\n",
      "Epoch 21/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2053 - accuracy: 0.6731 - val_loss: 0.1953 - val_accuracy: 0.6993\n",
      "Epoch 22/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2042 - accuracy: 0.6926 - val_loss: 0.2029 - val_accuracy: 0.6819\n",
      "Epoch 23/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2031 - accuracy: 0.6926 - val_loss: 0.2041 - val_accuracy: 0.6906\n",
      "Epoch 24/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2019 - accuracy: 0.6926 - val_loss: 0.1918 - val_accuracy: 0.7059\n",
      "Epoch 25/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2031 - accuracy: 0.6731 - val_loss: 0.1956 - val_accuracy: 0.7168\n",
      "Epoch 26/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2000 - accuracy: 0.7023 - val_loss: 0.1919 - val_accuracy: 0.7168\n",
      "Epoch 27/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2024 - accuracy: 0.6958 - val_loss: 0.1928 - val_accuracy: 0.7124\n",
      "Epoch 28/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.6796 - val_loss: 0.1942 - val_accuracy: 0.7255\n",
      "Epoch 29/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2012 - accuracy: 0.6926 - val_loss: 0.1911 - val_accuracy: 0.7146\n",
      "Epoch 30/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2033 - accuracy: 0.6958 - val_loss: 0.1933 - val_accuracy: 0.7342\n",
      "Epoch 31/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2002 - accuracy: 0.6926 - val_loss: 0.2021 - val_accuracy: 0.7059\n",
      "Epoch 32/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1952 - accuracy: 0.7087 - val_loss: 0.2178 - val_accuracy: 0.6275\n",
      "Epoch 33/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1998 - accuracy: 0.6861 - val_loss: 0.2021 - val_accuracy: 0.7015\n",
      "Epoch 34/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2030 - accuracy: 0.6537 - val_loss: 0.1932 - val_accuracy: 0.7342\n",
      "Epoch 35/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1986 - accuracy: 0.6828 - val_loss: 0.1935 - val_accuracy: 0.7320\n",
      "Epoch 36/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1986 - accuracy: 0.7087 - val_loss: 0.1954 - val_accuracy: 0.7255\n",
      "Epoch 37/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1965 - accuracy: 0.7023 - val_loss: 0.1908 - val_accuracy: 0.7233\n",
      "Epoch 38/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.7217 - val_loss: 0.1904 - val_accuracy: 0.7168\n",
      "Epoch 39/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.7087 - val_loss: 0.1942 - val_accuracy: 0.7211\n",
      "Epoch 40/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1943 - accuracy: 0.6796 - val_loss: 0.1899 - val_accuracy: 0.7298\n",
      "Epoch 41/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1986 - accuracy: 0.6958 - val_loss: 0.1917 - val_accuracy: 0.7255\n",
      "Epoch 42/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1950 - accuracy: 0.7249 - val_loss: 0.1920 - val_accuracy: 0.7168\n",
      "Epoch 43/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.7023 - val_loss: 0.2023 - val_accuracy: 0.6776\n",
      "Epoch 44/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1954 - accuracy: 0.7282 - val_loss: 0.1913 - val_accuracy: 0.7211\n",
      "Epoch 45/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1941 - accuracy: 0.7023 - val_loss: 0.2042 - val_accuracy: 0.6797\n",
      "Epoch 46/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1952 - accuracy: 0.6990 - val_loss: 0.1917 - val_accuracy: 0.7146\n",
      "Epoch 47/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1939 - accuracy: 0.6958 - val_loss: 0.1918 - val_accuracy: 0.7211\n",
      "Epoch 48/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1921 - accuracy: 0.6893 - val_loss: 0.1917 - val_accuracy: 0.7277\n",
      "Epoch 49/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1916 - accuracy: 0.7217 - val_loss: 0.1948 - val_accuracy: 0.6972\n",
      "Epoch 50/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1939 - accuracy: 0.7023 - val_loss: 0.1922 - val_accuracy: 0.7211\n",
      "Epoch 51/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1875 - accuracy: 0.7249 - val_loss: 0.1920 - val_accuracy: 0.7124\n",
      "Epoch 52/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1882 - accuracy: 0.7346 - val_loss: 0.1964 - val_accuracy: 0.6993\n",
      "Epoch 53/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1901 - accuracy: 0.6893 - val_loss: 0.1981 - val_accuracy: 0.6885\n",
      "Epoch 54/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1891 - accuracy: 0.7346 - val_loss: 0.1926 - val_accuracy: 0.7124\n",
      "Epoch 55/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1912 - accuracy: 0.6958 - val_loss: 0.1889 - val_accuracy: 0.7190\n",
      "Epoch 56/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1915 - accuracy: 0.6990 - val_loss: 0.1924 - val_accuracy: 0.7190\n",
      "Epoch 57/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1889 - accuracy: 0.7217 - val_loss: 0.1931 - val_accuracy: 0.7233\n",
      "Epoch 58/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1883 - accuracy: 0.6958 - val_loss: 0.1979 - val_accuracy: 0.6885\n",
      "Epoch 59/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1919 - accuracy: 0.7346 - val_loss: 0.1895 - val_accuracy: 0.7190\n",
      "Epoch 60/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1887 - accuracy: 0.6926 - val_loss: 0.1885 - val_accuracy: 0.7190\n",
      "Epoch 61/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1918 - accuracy: 0.7184 - val_loss: 0.1900 - val_accuracy: 0.7124\n",
      "Epoch 62/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1895 - accuracy: 0.7249 - val_loss: 0.1905 - val_accuracy: 0.7124\n",
      "Epoch 63/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1853 - accuracy: 0.7217 - val_loss: 0.1926 - val_accuracy: 0.7015\n",
      "Epoch 64/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1854 - accuracy: 0.7217 - val_loss: 0.1922 - val_accuracy: 0.7168\n",
      "Epoch 65/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1871 - accuracy: 0.6990 - val_loss: 0.1904 - val_accuracy: 0.7081\n",
      "Epoch 66/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1886 - accuracy: 0.7120 - val_loss: 0.1939 - val_accuracy: 0.6993\n",
      "Epoch 67/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1864 - accuracy: 0.7217 - val_loss: 0.1913 - val_accuracy: 0.7146\n",
      "Epoch 68/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1850 - accuracy: 0.7184 - val_loss: 0.1921 - val_accuracy: 0.7124\n",
      "Epoch 69/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1872 - accuracy: 0.7152 - val_loss: 0.1990 - val_accuracy: 0.6928\n",
      "Epoch 70/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1897 - accuracy: 0.7184 - val_loss: 0.1924 - val_accuracy: 0.7168\n",
      "Epoch 71/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1861 - accuracy: 0.7120 - val_loss: 0.1910 - val_accuracy: 0.7146\n",
      "Epoch 72/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1867 - accuracy: 0.7152 - val_loss: 0.1926 - val_accuracy: 0.6906\n",
      "Epoch 73/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1898 - accuracy: 0.7249 - val_loss: 0.1920 - val_accuracy: 0.7124\n",
      "Epoch 74/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1861 - accuracy: 0.7087 - val_loss: 0.1920 - val_accuracy: 0.7146\n",
      "Epoch 75/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1866 - accuracy: 0.7120 - val_loss: 0.1894 - val_accuracy: 0.7190\n",
      "Epoch 76/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1817 - accuracy: 0.7379 - val_loss: 0.1997 - val_accuracy: 0.6797\n",
      "Epoch 77/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1842 - accuracy: 0.7346 - val_loss: 0.1898 - val_accuracy: 0.7190\n",
      "Epoch 78/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1835 - accuracy: 0.7217 - val_loss: 0.1974 - val_accuracy: 0.6797\n",
      "Epoch 79/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1831 - accuracy: 0.7152 - val_loss: 0.1929 - val_accuracy: 0.7081\n",
      "Epoch 80/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1851 - accuracy: 0.7314 - val_loss: 0.1886 - val_accuracy: 0.7146\n",
      "Epoch 81/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1834 - accuracy: 0.7282 - val_loss: 0.1950 - val_accuracy: 0.6950\n",
      "Epoch 82/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1833 - accuracy: 0.7184 - val_loss: 0.1880 - val_accuracy: 0.7146\n",
      "Epoch 83/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.7443 - val_loss: 0.1990 - val_accuracy: 0.7037\n",
      "Epoch 84/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1836 - accuracy: 0.7346 - val_loss: 0.1927 - val_accuracy: 0.7124\n",
      "Epoch 85/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1865 - accuracy: 0.7217 - val_loss: 0.1920 - val_accuracy: 0.7059\n",
      "Epoch 86/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1795 - accuracy: 0.7476 - val_loss: 0.1890 - val_accuracy: 0.7211\n",
      "Epoch 87/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1848 - accuracy: 0.7120 - val_loss: 0.1908 - val_accuracy: 0.7168\n",
      "Epoch 88/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1848 - accuracy: 0.7217 - val_loss: 0.1903 - val_accuracy: 0.7233\n",
      "Epoch 89/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1798 - accuracy: 0.7379 - val_loss: 0.1881 - val_accuracy: 0.7168\n",
      "Epoch 90/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1795 - accuracy: 0.7346 - val_loss: 0.1881 - val_accuracy: 0.7124\n",
      "Epoch 91/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1814 - accuracy: 0.7249 - val_loss: 0.1915 - val_accuracy: 0.7124\n",
      "Epoch 92/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1851 - accuracy: 0.7055 - val_loss: 0.1902 - val_accuracy: 0.7146\n",
      "Epoch 93/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1773 - accuracy: 0.7379 - val_loss: 0.1970 - val_accuracy: 0.7059\n",
      "Epoch 94/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1833 - accuracy: 0.7282 - val_loss: 0.1897 - val_accuracy: 0.7124\n",
      "Epoch 95/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1803 - accuracy: 0.7152 - val_loss: 0.1874 - val_accuracy: 0.7190\n",
      "Epoch 96/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1821 - accuracy: 0.7282 - val_loss: 0.1910 - val_accuracy: 0.7102\n",
      "Epoch 97/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1832 - accuracy: 0.7184 - val_loss: 0.1891 - val_accuracy: 0.7124\n",
      "Epoch 98/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.7217 - val_loss: 0.1929 - val_accuracy: 0.7168\n",
      "Epoch 99/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1776 - accuracy: 0.7346 - val_loss: 0.1905 - val_accuracy: 0.7146\n",
      "Epoch 100/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1780 - accuracy: 0.7346 - val_loss: 0.1892 - val_accuracy: 0.7168\n",
      "Epoch 101/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1824 - accuracy: 0.7184 - val_loss: 0.1912 - val_accuracy: 0.7102\n",
      "Epoch 102/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.7217 - val_loss: 0.1889 - val_accuracy: 0.7277\n",
      "Epoch 103/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1749 - accuracy: 0.7379 - val_loss: 0.1907 - val_accuracy: 0.7211\n",
      "Epoch 104/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.7508 - val_loss: 0.1924 - val_accuracy: 0.7037\n",
      "Epoch 105/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1772 - accuracy: 0.7476 - val_loss: 0.1941 - val_accuracy: 0.7059\n",
      "Epoch 106/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7379 - val_loss: 0.1911 - val_accuracy: 0.7168\n",
      "Epoch 107/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1783 - accuracy: 0.7411 - val_loss: 0.1927 - val_accuracy: 0.6993\n",
      "Epoch 108/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.7249 - val_loss: 0.1862 - val_accuracy: 0.7211\n",
      "Epoch 109/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1782 - accuracy: 0.7282 - val_loss: 0.1924 - val_accuracy: 0.7102\n",
      "Epoch 110/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.7476 - val_loss: 0.1942 - val_accuracy: 0.7059\n",
      "Epoch 111/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1778 - accuracy: 0.7443 - val_loss: 0.1920 - val_accuracy: 0.6993\n",
      "Epoch 112/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1764 - accuracy: 0.7476 - val_loss: 0.1989 - val_accuracy: 0.6928\n",
      "Epoch 113/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1763 - accuracy: 0.7443 - val_loss: 0.1895 - val_accuracy: 0.7190\n",
      "Epoch 114/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1756 - accuracy: 0.7443 - val_loss: 0.1942 - val_accuracy: 0.7146\n",
      "Epoch 115/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1769 - accuracy: 0.7411 - val_loss: 0.1899 - val_accuracy: 0.7255\n",
      "Epoch 116/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1784 - accuracy: 0.7282 - val_loss: 0.1872 - val_accuracy: 0.7102\n",
      "Epoch 117/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.7443 - val_loss: 0.1893 - val_accuracy: 0.7037\n",
      "Epoch 118/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1765 - accuracy: 0.7346 - val_loss: 0.1907 - val_accuracy: 0.7190\n",
      "Epoch 119/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1724 - accuracy: 0.7702 - val_loss: 0.1895 - val_accuracy: 0.7081\n",
      "Epoch 120/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1767 - accuracy: 0.7314 - val_loss: 0.1990 - val_accuracy: 0.6797\n",
      "Epoch 121/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7379 - val_loss: 0.1879 - val_accuracy: 0.7124\n",
      "Epoch 122/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1741 - accuracy: 0.7508 - val_loss: 0.2054 - val_accuracy: 0.6558\n",
      "Epoch 123/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1750 - accuracy: 0.7476 - val_loss: 0.1874 - val_accuracy: 0.7190\n",
      "Epoch 124/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1752 - accuracy: 0.7605 - val_loss: 0.1930 - val_accuracy: 0.7015\n",
      "Epoch 125/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1740 - accuracy: 0.7314 - val_loss: 0.1874 - val_accuracy: 0.7102\n",
      "Epoch 126/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1722 - accuracy: 0.7346 - val_loss: 0.1986 - val_accuracy: 0.6993\n",
      "Epoch 127/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1772 - accuracy: 0.7184 - val_loss: 0.1867 - val_accuracy: 0.7124\n",
      "Epoch 128/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1751 - accuracy: 0.7605 - val_loss: 0.1876 - val_accuracy: 0.7168\n",
      "Epoch 129/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1713 - accuracy: 0.7379 - val_loss: 0.1879 - val_accuracy: 0.7124\n",
      "Epoch 130/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1738 - accuracy: 0.7443 - val_loss: 0.1897 - val_accuracy: 0.7037\n",
      "Epoch 131/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1766 - accuracy: 0.7152 - val_loss: 0.1865 - val_accuracy: 0.6950\n",
      "Epoch 132/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.7476 - val_loss: 0.1877 - val_accuracy: 0.7102\n",
      "Epoch 133/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 0.7508 - val_loss: 0.1969 - val_accuracy: 0.7015\n",
      "Epoch 134/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1730 - accuracy: 0.7443 - val_loss: 0.1926 - val_accuracy: 0.7015\n",
      "Epoch 135/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1716 - accuracy: 0.7540 - val_loss: 0.2140 - val_accuracy: 0.6383\n",
      "Epoch 136/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1710 - accuracy: 0.7508 - val_loss: 0.2023 - val_accuracy: 0.6841\n",
      "Epoch 137/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1751 - accuracy: 0.7120 - val_loss: 0.1909 - val_accuracy: 0.7190\n",
      "Epoch 138/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1716 - accuracy: 0.7476 - val_loss: 0.1879 - val_accuracy: 0.7037\n",
      "Epoch 139/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1722 - accuracy: 0.7249 - val_loss: 0.1878 - val_accuracy: 0.7146\n",
      "Epoch 140/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1715 - accuracy: 0.7346 - val_loss: 0.1907 - val_accuracy: 0.7211\n",
      "Epoch 141/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1702 - accuracy: 0.7670 - val_loss: 0.1908 - val_accuracy: 0.7037\n",
      "Epoch 142/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1748 - accuracy: 0.7379 - val_loss: 0.1888 - val_accuracy: 0.7190\n",
      "Epoch 143/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1701 - accuracy: 0.7508 - val_loss: 0.1897 - val_accuracy: 0.7059\n",
      "Epoch 144/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1674 - accuracy: 0.7443 - val_loss: 0.1882 - val_accuracy: 0.7081\n",
      "Epoch 145/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1735 - accuracy: 0.7314 - val_loss: 0.1884 - val_accuracy: 0.7124\n",
      "Epoch 146/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1734 - accuracy: 0.7346 - val_loss: 0.1902 - val_accuracy: 0.7037\n",
      "Epoch 147/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1708 - accuracy: 0.7346 - val_loss: 0.1866 - val_accuracy: 0.7168\n",
      "Epoch 148/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1716 - accuracy: 0.7411 - val_loss: 0.1933 - val_accuracy: 0.6972\n",
      "Epoch 149/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1699 - accuracy: 0.7217 - val_loss: 0.1863 - val_accuracy: 0.7255\n",
      "Epoch 150/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1686 - accuracy: 0.7411 - val_loss: 0.1862 - val_accuracy: 0.7124\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.7124\n",
      "\n",
      "  [model1] model końcowy: [0.1861950010061264, 0.7124183177947998]\n",
      "Epoch 1/150\n",
      "31/31 [==============================] - 1s 7ms/step - loss: 0.2455 - accuracy: 0.6149 - val_loss: 0.2382 - val_accuracy: 0.6754\n",
      "Epoch 2/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2413 - accuracy: 0.6149 - val_loss: 0.2320 - val_accuracy: 0.6754\n",
      "Epoch 3/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2384 - accuracy: 0.6149 - val_loss: 0.2277 - val_accuracy: 0.6754\n",
      "Epoch 4/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2364 - accuracy: 0.6149 - val_loss: 0.2246 - val_accuracy: 0.6754\n",
      "Epoch 5/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2352 - accuracy: 0.6149 - val_loss: 0.2221 - val_accuracy: 0.6754\n",
      "Epoch 6/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2345 - accuracy: 0.6149 - val_loss: 0.2209 - val_accuracy: 0.6754\n",
      "Epoch 7/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2339 - accuracy: 0.6149 - val_loss: 0.2197 - val_accuracy: 0.6754\n",
      "Epoch 8/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2331 - accuracy: 0.6149 - val_loss: 0.2191 - val_accuracy: 0.6754\n",
      "Epoch 9/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2323 - accuracy: 0.6149 - val_loss: 0.2187 - val_accuracy: 0.6754\n",
      "Epoch 10/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2316 - accuracy: 0.6149 - val_loss: 0.2169 - val_accuracy: 0.6754\n",
      "Epoch 11/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2303 - accuracy: 0.6149 - val_loss: 0.2158 - val_accuracy: 0.6754\n",
      "Epoch 12/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2302 - accuracy: 0.6149 - val_loss: 0.2156 - val_accuracy: 0.6754\n",
      "Epoch 13/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2292 - accuracy: 0.6149 - val_loss: 0.2154 - val_accuracy: 0.6754\n",
      "Epoch 14/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2284 - accuracy: 0.6149 - val_loss: 0.2135 - val_accuracy: 0.6754\n",
      "Epoch 15/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2271 - accuracy: 0.6181 - val_loss: 0.2130 - val_accuracy: 0.6754\n",
      "Epoch 16/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2260 - accuracy: 0.6181 - val_loss: 0.2126 - val_accuracy: 0.6710\n",
      "Epoch 17/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2246 - accuracy: 0.6214 - val_loss: 0.2152 - val_accuracy: 0.6732\n",
      "Epoch 18/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2239 - accuracy: 0.6311 - val_loss: 0.2111 - val_accuracy: 0.6732\n",
      "Epoch 19/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2223 - accuracy: 0.6246 - val_loss: 0.2113 - val_accuracy: 0.6732\n",
      "Epoch 20/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2208 - accuracy: 0.6343 - val_loss: 0.2089 - val_accuracy: 0.6819\n",
      "Epoch 21/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2198 - accuracy: 0.6375 - val_loss: 0.2104 - val_accuracy: 0.6841\n",
      "Epoch 22/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2181 - accuracy: 0.6343 - val_loss: 0.2071 - val_accuracy: 0.6841\n",
      "Epoch 23/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2162 - accuracy: 0.6440 - val_loss: 0.2092 - val_accuracy: 0.6950\n",
      "Epoch 24/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2173 - accuracy: 0.6537 - val_loss: 0.2084 - val_accuracy: 0.6928\n",
      "Epoch 25/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2146 - accuracy: 0.6440 - val_loss: 0.2081 - val_accuracy: 0.6885\n",
      "Epoch 26/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2133 - accuracy: 0.6408 - val_loss: 0.2076 - val_accuracy: 0.6885\n",
      "Epoch 27/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.6408 - val_loss: 0.2089 - val_accuracy: 0.6906\n",
      "Epoch 28/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2116 - accuracy: 0.6570 - val_loss: 0.2108 - val_accuracy: 0.6536\n",
      "Epoch 29/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2116 - accuracy: 0.6343 - val_loss: 0.2060 - val_accuracy: 0.6732\n",
      "Epoch 30/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2091 - accuracy: 0.6667 - val_loss: 0.2070 - val_accuracy: 0.6732\n",
      "Epoch 31/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2103 - accuracy: 0.6570 - val_loss: 0.2050 - val_accuracy: 0.6688\n",
      "Epoch 32/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.6764 - val_loss: 0.2029 - val_accuracy: 0.6906\n",
      "Epoch 33/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2060 - accuracy: 0.6602 - val_loss: 0.2096 - val_accuracy: 0.6492\n",
      "Epoch 34/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2066 - accuracy: 0.6764 - val_loss: 0.2086 - val_accuracy: 0.6427\n",
      "Epoch 35/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2057 - accuracy: 0.6505 - val_loss: 0.2044 - val_accuracy: 0.6601\n",
      "Epoch 36/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2054 - accuracy: 0.6699 - val_loss: 0.2020 - val_accuracy: 0.6754\n",
      "Epoch 37/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2068 - accuracy: 0.6634 - val_loss: 0.2054 - val_accuracy: 0.6623\n",
      "Epoch 38/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2000 - accuracy: 0.6958 - val_loss: 0.2099 - val_accuracy: 0.6362\n",
      "Epoch 39/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2025 - accuracy: 0.6828 - val_loss: 0.2035 - val_accuracy: 0.6645\n",
      "Epoch 40/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.6861 - val_loss: 0.2019 - val_accuracy: 0.6776\n",
      "Epoch 41/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2016 - accuracy: 0.6990 - val_loss: 0.2011 - val_accuracy: 0.6645\n",
      "Epoch 42/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2020 - accuracy: 0.6990 - val_loss: 0.2151 - val_accuracy: 0.6296\n",
      "Epoch 43/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2028 - accuracy: 0.6893 - val_loss: 0.1993 - val_accuracy: 0.7298\n",
      "Epoch 44/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.6764 - val_loss: 0.1997 - val_accuracy: 0.6885\n",
      "Epoch 45/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1985 - accuracy: 0.6796 - val_loss: 0.1990 - val_accuracy: 0.7146\n",
      "Epoch 46/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2017 - accuracy: 0.6634 - val_loss: 0.2070 - val_accuracy: 0.6449\n",
      "Epoch 47/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2032 - accuracy: 0.6667 - val_loss: 0.1975 - val_accuracy: 0.7124\n",
      "Epoch 48/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.7120 - val_loss: 0.2039 - val_accuracy: 0.6950\n",
      "Epoch 49/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2018 - accuracy: 0.6828 - val_loss: 0.1963 - val_accuracy: 0.7102\n",
      "Epoch 50/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1994 - accuracy: 0.6828 - val_loss: 0.1979 - val_accuracy: 0.7015\n",
      "Epoch 51/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1990 - accuracy: 0.6893 - val_loss: 0.1978 - val_accuracy: 0.7081\n",
      "Epoch 52/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1948 - accuracy: 0.7055 - val_loss: 0.2065 - val_accuracy: 0.6580\n",
      "Epoch 53/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1953 - accuracy: 0.6958 - val_loss: 0.2005 - val_accuracy: 0.7037\n",
      "Epoch 54/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1962 - accuracy: 0.7087 - val_loss: 0.2016 - val_accuracy: 0.6928\n",
      "Epoch 55/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1974 - accuracy: 0.6926 - val_loss: 0.1956 - val_accuracy: 0.7059\n",
      "Epoch 56/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1948 - accuracy: 0.7282 - val_loss: 0.2019 - val_accuracy: 0.6819\n",
      "Epoch 57/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1952 - accuracy: 0.6958 - val_loss: 0.1941 - val_accuracy: 0.7146\n",
      "Epoch 58/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1894 - accuracy: 0.7184 - val_loss: 0.2169 - val_accuracy: 0.6471\n",
      "Epoch 59/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1879 - accuracy: 0.7314 - val_loss: 0.1936 - val_accuracy: 0.7190\n",
      "Epoch 60/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1948 - accuracy: 0.7152 - val_loss: 0.1943 - val_accuracy: 0.7081\n",
      "Epoch 61/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1952 - accuracy: 0.7087 - val_loss: 0.1951 - val_accuracy: 0.7081\n",
      "Epoch 62/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.7314 - val_loss: 0.1952 - val_accuracy: 0.7037\n",
      "Epoch 63/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1884 - accuracy: 0.7184 - val_loss: 0.2047 - val_accuracy: 0.7037\n",
      "Epoch 64/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1932 - accuracy: 0.7087 - val_loss: 0.2005 - val_accuracy: 0.6885\n",
      "Epoch 65/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1919 - accuracy: 0.7120 - val_loss: 0.1932 - val_accuracy: 0.7081\n",
      "Epoch 66/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1936 - accuracy: 0.7152 - val_loss: 0.1956 - val_accuracy: 0.7102\n",
      "Epoch 67/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1918 - accuracy: 0.7120 - val_loss: 0.1967 - val_accuracy: 0.7059\n",
      "Epoch 68/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1920 - accuracy: 0.7184 - val_loss: 0.1945 - val_accuracy: 0.7015\n",
      "Epoch 69/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1912 - accuracy: 0.7217 - val_loss: 0.2079 - val_accuracy: 0.6536\n",
      "Epoch 70/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1942 - accuracy: 0.7120 - val_loss: 0.1947 - val_accuracy: 0.7102\n",
      "Epoch 71/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.6990 - val_loss: 0.1925 - val_accuracy: 0.7081\n",
      "Epoch 72/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1870 - accuracy: 0.7249 - val_loss: 0.2040 - val_accuracy: 0.6688\n",
      "Epoch 73/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1916 - accuracy: 0.7184 - val_loss: 0.2048 - val_accuracy: 0.6776\n",
      "Epoch 74/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1956 - accuracy: 0.6958 - val_loss: 0.1938 - val_accuracy: 0.7124\n",
      "Epoch 75/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1875 - accuracy: 0.7282 - val_loss: 0.2149 - val_accuracy: 0.6383\n",
      "Epoch 76/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1834 - accuracy: 0.7346 - val_loss: 0.1972 - val_accuracy: 0.7059\n",
      "Epoch 77/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1935 - accuracy: 0.7087 - val_loss: 0.1968 - val_accuracy: 0.6950\n",
      "Epoch 78/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1927 - accuracy: 0.6990 - val_loss: 0.1969 - val_accuracy: 0.6972\n",
      "Epoch 79/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1902 - accuracy: 0.7443 - val_loss: 0.2050 - val_accuracy: 0.6492\n",
      "Epoch 80/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1858 - accuracy: 0.7282 - val_loss: 0.2008 - val_accuracy: 0.6885\n",
      "Epoch 81/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1917 - accuracy: 0.7184 - val_loss: 0.1989 - val_accuracy: 0.6885\n",
      "Epoch 82/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1913 - accuracy: 0.7087 - val_loss: 0.1960 - val_accuracy: 0.7102\n",
      "Epoch 83/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1885 - accuracy: 0.7120 - val_loss: 0.1946 - val_accuracy: 0.7168\n",
      "Epoch 84/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1892 - accuracy: 0.7087 - val_loss: 0.1969 - val_accuracy: 0.7102\n",
      "Epoch 85/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1873 - accuracy: 0.7282 - val_loss: 0.1996 - val_accuracy: 0.6972\n",
      "Epoch 86/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1899 - accuracy: 0.7023 - val_loss: 0.2071 - val_accuracy: 0.6688\n",
      "Epoch 87/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1893 - accuracy: 0.6990 - val_loss: 0.1965 - val_accuracy: 0.7102\n",
      "Epoch 88/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1888 - accuracy: 0.7217 - val_loss: 0.1931 - val_accuracy: 0.6993\n",
      "Epoch 89/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1860 - accuracy: 0.7411 - val_loss: 0.2088 - val_accuracy: 0.6340\n",
      "Epoch 90/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1799 - accuracy: 0.7379 - val_loss: 0.1983 - val_accuracy: 0.7037\n",
      "Epoch 91/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1909 - accuracy: 0.6958 - val_loss: 0.1987 - val_accuracy: 0.7015\n",
      "Epoch 92/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1879 - accuracy: 0.7217 - val_loss: 0.1960 - val_accuracy: 0.7081\n",
      "Epoch 93/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1860 - accuracy: 0.7217 - val_loss: 0.1990 - val_accuracy: 0.6993\n",
      "Epoch 94/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1843 - accuracy: 0.7120 - val_loss: 0.1929 - val_accuracy: 0.7124\n",
      "Epoch 95/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1869 - accuracy: 0.7087 - val_loss: 0.1909 - val_accuracy: 0.7081\n",
      "Epoch 96/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1872 - accuracy: 0.7087 - val_loss: 0.1957 - val_accuracy: 0.7146\n",
      "Epoch 97/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1907 - accuracy: 0.6926 - val_loss: 0.1949 - val_accuracy: 0.7081\n",
      "Epoch 98/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1869 - accuracy: 0.7379 - val_loss: 0.2008 - val_accuracy: 0.6906\n",
      "Epoch 99/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1848 - accuracy: 0.7379 - val_loss: 0.1929 - val_accuracy: 0.7059\n",
      "Epoch 100/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1883 - accuracy: 0.6926 - val_loss: 0.1948 - val_accuracy: 0.7015\n",
      "Epoch 101/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1886 - accuracy: 0.7184 - val_loss: 0.2002 - val_accuracy: 0.6885\n",
      "Epoch 102/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1850 - accuracy: 0.7314 - val_loss: 0.1946 - val_accuracy: 0.7102\n",
      "Epoch 103/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1804 - accuracy: 0.7379 - val_loss: 0.1954 - val_accuracy: 0.6928\n",
      "Epoch 104/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1837 - accuracy: 0.7443 - val_loss: 0.1949 - val_accuracy: 0.7059\n",
      "Epoch 105/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1875 - accuracy: 0.7120 - val_loss: 0.1905 - val_accuracy: 0.7255\n",
      "Epoch 106/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1836 - accuracy: 0.7411 - val_loss: 0.1973 - val_accuracy: 0.7015\n",
      "Epoch 107/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1817 - accuracy: 0.7508 - val_loss: 0.1914 - val_accuracy: 0.7059\n",
      "Epoch 108/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1833 - accuracy: 0.7184 - val_loss: 0.2101 - val_accuracy: 0.6645\n",
      "Epoch 109/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1840 - accuracy: 0.7217 - val_loss: 0.1929 - val_accuracy: 0.7146\n",
      "Epoch 110/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1846 - accuracy: 0.7379 - val_loss: 0.1912 - val_accuracy: 0.7081\n",
      "Epoch 111/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1767 - accuracy: 0.7508 - val_loss: 0.2041 - val_accuracy: 0.6710\n",
      "Epoch 112/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1849 - accuracy: 0.7217 - val_loss: 0.1956 - val_accuracy: 0.7168\n",
      "Epoch 113/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1775 - accuracy: 0.7508 - val_loss: 0.2135 - val_accuracy: 0.6492\n",
      "Epoch 114/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1860 - accuracy: 0.7087 - val_loss: 0.1952 - val_accuracy: 0.7146\n",
      "Epoch 115/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1797 - accuracy: 0.7638 - val_loss: 0.1935 - val_accuracy: 0.7124\n",
      "Epoch 116/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1821 - accuracy: 0.7379 - val_loss: 0.1917 - val_accuracy: 0.7168\n",
      "Epoch 117/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1770 - accuracy: 0.7411 - val_loss: 0.1943 - val_accuracy: 0.7059\n",
      "Epoch 118/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1766 - accuracy: 0.7443 - val_loss: 0.1942 - val_accuracy: 0.7102\n",
      "Epoch 119/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1772 - accuracy: 0.7282 - val_loss: 0.1982 - val_accuracy: 0.7059\n",
      "Epoch 120/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1860 - accuracy: 0.7184 - val_loss: 0.1923 - val_accuracy: 0.7233\n",
      "Epoch 121/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7476 - val_loss: 0.1874 - val_accuracy: 0.7233\n",
      "Epoch 122/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1777 - accuracy: 0.7767 - val_loss: 0.1976 - val_accuracy: 0.7059\n",
      "Epoch 123/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1805 - accuracy: 0.7346 - val_loss: 0.2048 - val_accuracy: 0.6819\n",
      "Epoch 124/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.7249 - val_loss: 0.1937 - val_accuracy: 0.7124\n",
      "Epoch 125/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.7573 - val_loss: 0.2014 - val_accuracy: 0.6993\n",
      "Epoch 126/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1814 - accuracy: 0.7184 - val_loss: 0.1929 - val_accuracy: 0.7255\n",
      "Epoch 127/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1850 - accuracy: 0.7249 - val_loss: 0.1941 - val_accuracy: 0.7190\n",
      "Epoch 128/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.7411 - val_loss: 0.1949 - val_accuracy: 0.7320\n",
      "Epoch 129/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1791 - accuracy: 0.7346 - val_loss: 0.1945 - val_accuracy: 0.6950\n",
      "Epoch 130/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.7217 - val_loss: 0.1902 - val_accuracy: 0.7168\n",
      "Epoch 131/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1758 - accuracy: 0.7508 - val_loss: 0.1880 - val_accuracy: 0.7255\n",
      "Epoch 132/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.7314 - val_loss: 0.1950 - val_accuracy: 0.7124\n",
      "Epoch 133/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.7346 - val_loss: 0.2026 - val_accuracy: 0.7015\n",
      "Epoch 134/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1831 - accuracy: 0.7282 - val_loss: 0.1894 - val_accuracy: 0.7298\n",
      "Epoch 135/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1744 - accuracy: 0.7508 - val_loss: 0.2002 - val_accuracy: 0.6928\n",
      "Epoch 136/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1843 - accuracy: 0.7184 - val_loss: 0.1945 - val_accuracy: 0.7168\n",
      "Epoch 137/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1710 - accuracy: 0.7540 - val_loss: 0.1904 - val_accuracy: 0.7342\n",
      "Epoch 138/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1779 - accuracy: 0.7476 - val_loss: 0.1925 - val_accuracy: 0.7015\n",
      "Epoch 139/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1809 - accuracy: 0.7476 - val_loss: 0.1887 - val_accuracy: 0.7342\n",
      "Epoch 140/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1720 - accuracy: 0.7476 - val_loss: 0.2045 - val_accuracy: 0.6776\n",
      "Epoch 141/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1800 - accuracy: 0.7314 - val_loss: 0.1913 - val_accuracy: 0.7364\n",
      "Epoch 142/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.7282 - val_loss: 0.1991 - val_accuracy: 0.6950\n",
      "Epoch 143/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1769 - accuracy: 0.7508 - val_loss: 0.1909 - val_accuracy: 0.7255\n",
      "Epoch 144/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1780 - accuracy: 0.7605 - val_loss: 0.1891 - val_accuracy: 0.7516\n",
      "Epoch 145/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1767 - accuracy: 0.7573 - val_loss: 0.1952 - val_accuracy: 0.7190\n",
      "Epoch 146/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1807 - accuracy: 0.7346 - val_loss: 0.1890 - val_accuracy: 0.7298\n",
      "Epoch 147/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1727 - accuracy: 0.7443 - val_loss: 0.2019 - val_accuracy: 0.6885\n",
      "Epoch 148/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1782 - accuracy: 0.7476 - val_loss: 0.1962 - val_accuracy: 0.7124\n",
      "Epoch 149/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1793 - accuracy: 0.7249 - val_loss: 0.1874 - val_accuracy: 0.7233\n",
      "Epoch 150/150\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1760 - accuracy: 0.7476 - val_loss: 0.1922 - val_accuracy: 0.7298\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.7298\n",
      "\n",
      "  [model2] model końcowy: [0.19223707914352417, 0.7298474907875061]\n",
      "46/46 [==============================] - 0s 987us/step - loss: 0.1944 - accuracy: 0.6906\n",
      "46/46 [==============================] - 0s 991us/step - loss: 0.1946 - accuracy: 0.7255\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.7059\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2197 - accuracy: 0.6492\n",
      "46/46 [==============================] - 0s 967us/step - loss: 0.2012 - accuracy: 0.6972\n",
      "46/46 [==============================] - 0s 939us/step - loss: 0.2173 - accuracy: 0.6688\n",
      "46/46 [==============================] - 0s 915us/step - loss: 0.2222 - accuracy: 0.6972\n",
      "46/46 [==============================] - 0s 970us/step - loss: 0.2335 - accuracy: 0.6449\n",
      "46/46 [==============================] - 0s 988us/step - loss: 0.2199 - accuracy: 0.7146\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.6950\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.6885\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.6688\n",
      "46/46 [==============================] - 0s 952us/step - loss: 0.2382 - accuracy: 0.6710\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.7015\n",
      "46/46 [==============================] - 0s 928us/step - loss: 0.2436 - accuracy: 0.6776\n",
      "46/46 [==============================] - 0s 994us/step - loss: 0.2217 - accuracy: 0.6972\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.6906\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.7146\n",
      "46/46 [==============================] - 0s 981us/step - loss: 0.2535 - accuracy: 0.6710\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.6972\n",
      "\n",
      " [DLA JEDNEJ WARSTWY] LOSS:       0.22414749711751938\n",
      " [DLA JEDNEJ WARSTWY] ACCURACY:   0.6904139399528504\n",
      "---------------------------\n",
      " [DLA DWOCH WARSTW] LOSS:       0.22064829766750335\n",
      " [DLA DWOCH WARSTW] ACCURACY:   0.6862744987010956\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------\n",
    "import sys\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "path_nb = r'/content/drive/My Drive/Colab Notebooks/'\n",
    "sys.path.append(path_nb)\n",
    "\n",
    "#-------------------------------------------------\n",
    "\n",
    "load_dataset = np.loadtxt(path_nb + \"pima-indians-diabetes.data.csv\", delimiter = ',')\n",
    "X = load_dataset[:, 0:8]\n",
    "Y = load_dataset[:, 8]\n",
    "data_x = X[:309]\n",
    "data_y = Y[:309]\n",
    "val_x = X[309:]\n",
    "val_y = Y[309:]\n",
    "\n",
    "\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(30, input_dim=8, use_bias=True, activation='tanh', kernel_initializer='random_uniform', bias_initializer='random_uniform'))\n",
    "model1.add(Dense(1, use_bias=True, activation='sigmoid', kernel_initializer='random_uniform', bias_initializer='random_uniform'))\n",
    "rms = tf.keras.optimizers.RMSprop(lr=0.001)\n",
    "model1.compile(loss='mse', optimizer=rms, metrics=['accuracy'])\n",
    "model1.fit(data_x, data_y, epochs=150, verbose=1, batch_size=10, validation_data=(val_x, val_y))\n",
    "score = model1.evaluate(val_x, val_y, batch_size=10)\n",
    "print('\\n  [model1] model końcowy: {}'.format(score))\n",
    "\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(12, input_dim=8, use_bias=True, activation='tanh', kernel_initializer='random_uniform', bias_initializer='random_uniform'))\n",
    "model2.add(Dense(8, use_bias=True, activation='tanh', kernel_initializer='random_uniform', bias_initializer='random_uniform'))\n",
    "model2.add(Dense(1, use_bias=True, activation='sigmoid', kernel_initializer='random_uniform', bias_initializer='random_uniform'))\n",
    "rms = tf.keras.optimizers.RMSprop(lr=0.001)\n",
    "model2.compile(loss='mse', optimizer=rms, metrics=['accuracy'])\n",
    "model2.fit(data_x, data_y, epochs=150, verbose=1, batch_size=10, validation_data=(val_x, val_y))\n",
    "score = model2.evaluate(val_x, val_y, batch_size=10)\n",
    "print('\\n  [model2] model końcowy: {}'.format(score))\n",
    "\n",
    "\n",
    "scale = np.zeros(shape=(10,2,2))\n",
    "for i in range(0, 10):\n",
    "    np.random.seed(i)\n",
    "    \n",
    "    model1.fit(data_x, data_y, epochs=150, verbose=0, batch_size=10, validation_data=(val_x, val_y))\n",
    "    scale[i, 0] = model1.evaluate(val_x, val_y, batch_size=10)\n",
    "    \n",
    "    model2.fit(data_x, data_y, epochs=150, verbose=0, batch_size=10, validation_data=(val_x, val_y))\n",
    "    scale[i, 1] = model2.evaluate(val_x, val_y, batch_size=10)\n",
    "\n",
    "\n",
    "\n",
    "print('\\n [DLA JEDNEJ WARSTWY] LOSS:       {}'.format(scale[:, 0, 0].mean()))\n",
    "print(' [DLA JEDNEJ WARSTWY] ACCURACY:   {}'.format(scale[:, 0, 1].mean()))\n",
    "print('---------------------------')\n",
    "print(' [DLA DWOCH WARSTW] LOSS:       {}'.format(scale[:, 1, 0].mean()))\n",
    "print(' [DLA DWOCH WARSTW] ACCURACY:   {}'.format(scale[:, 1, 1].mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFD4AIrBffbv"
   },
   "source": [
    "TWOJE KOMENTARZE I WNIOSKI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJ-HglDPTipF"
   },
   "source": [
    "Dla jednej i dwóch warstw ukrytych otrzymane wyniki są dosyć bliskie  (rożnica między nimi wynosi mniej więcej : około 0.004).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMVC3S4Mq3Ep"
   },
   "source": [
    "Type Markdown and LaTeX:  𝛼2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C57dALyNj4Se"
   },
   "source": [
    "&copy; Katedra Informatyki, Politechnika Krakowska"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "135968_Agabalaev_Pavel_NN_Lab_3_Zadania.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
